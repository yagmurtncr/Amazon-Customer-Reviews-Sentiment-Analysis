{
  "best_global_step": 12500,
  "best_metric": 0.79555,
  "best_model_checkpoint": "./sentiment_model_distilbert/checkpoint-12500",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 12500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008,
      "grad_norm": 16.105514526367188,
      "learning_rate": 4.9802e-05,
      "loss": 1.0355,
      "step": 100
    },
    {
      "epoch": 0.016,
      "grad_norm": 7.584198474884033,
      "learning_rate": 4.9602000000000004e-05,
      "loss": 0.8547,
      "step": 200
    },
    {
      "epoch": 0.024,
      "grad_norm": 10.737046241760254,
      "learning_rate": 4.9402000000000006e-05,
      "loss": 0.805,
      "step": 300
    },
    {
      "epoch": 0.032,
      "grad_norm": 14.335624694824219,
      "learning_rate": 4.9202e-05,
      "loss": 0.7629,
      "step": 400
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.388289451599121,
      "learning_rate": 4.9002e-05,
      "loss": 0.7998,
      "step": 500
    },
    {
      "epoch": 0.048,
      "grad_norm": 10.921180725097656,
      "learning_rate": 4.8802000000000005e-05,
      "loss": 0.7055,
      "step": 600
    },
    {
      "epoch": 0.056,
      "grad_norm": 7.506641387939453,
      "learning_rate": 4.8602e-05,
      "loss": 0.6495,
      "step": 700
    },
    {
      "epoch": 0.064,
      "grad_norm": 5.705341339111328,
      "learning_rate": 4.8402e-05,
      "loss": 0.7152,
      "step": 800
    },
    {
      "epoch": 0.072,
      "grad_norm": 5.118066310882568,
      "learning_rate": 4.8202000000000004e-05,
      "loss": 0.838,
      "step": 900
    },
    {
      "epoch": 0.08,
      "grad_norm": 12.10324478149414,
      "learning_rate": 4.8002000000000006e-05,
      "loss": 0.6784,
      "step": 1000
    },
    {
      "epoch": 0.088,
      "grad_norm": 2.3076603412628174,
      "learning_rate": 4.7802e-05,
      "loss": 0.7045,
      "step": 1100
    },
    {
      "epoch": 0.096,
      "grad_norm": 10.021269798278809,
      "learning_rate": 4.7602e-05,
      "loss": 0.7564,
      "step": 1200
    },
    {
      "epoch": 0.104,
      "grad_norm": 3.9685754776000977,
      "learning_rate": 4.7402000000000005e-05,
      "loss": 0.7185,
      "step": 1300
    },
    {
      "epoch": 0.112,
      "grad_norm": 10.025131225585938,
      "learning_rate": 4.7202e-05,
      "loss": 0.6635,
      "step": 1400
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.702301025390625,
      "learning_rate": 4.7002e-05,
      "loss": 0.5931,
      "step": 1500
    },
    {
      "epoch": 0.128,
      "grad_norm": 15.647908210754395,
      "learning_rate": 4.6802000000000004e-05,
      "loss": 0.7024,
      "step": 1600
    },
    {
      "epoch": 0.136,
      "grad_norm": 7.040090084075928,
      "learning_rate": 4.6602e-05,
      "loss": 0.6412,
      "step": 1700
    },
    {
      "epoch": 0.144,
      "grad_norm": 6.943471908569336,
      "learning_rate": 4.6402e-05,
      "loss": 0.661,
      "step": 1800
    },
    {
      "epoch": 0.152,
      "grad_norm": 6.252651691436768,
      "learning_rate": 4.6202e-05,
      "loss": 0.6491,
      "step": 1900
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.98859691619873,
      "learning_rate": 4.6002e-05,
      "loss": 0.6703,
      "step": 2000
    },
    {
      "epoch": 0.168,
      "grad_norm": 3.9293153285980225,
      "learning_rate": 4.5802e-05,
      "loss": 0.6337,
      "step": 2100
    },
    {
      "epoch": 0.176,
      "grad_norm": 5.479185581207275,
      "learning_rate": 4.5602e-05,
      "loss": 0.6786,
      "step": 2200
    },
    {
      "epoch": 0.184,
      "grad_norm": 3.1767797470092773,
      "learning_rate": 4.5402000000000003e-05,
      "loss": 0.6579,
      "step": 2300
    },
    {
      "epoch": 0.192,
      "grad_norm": 7.63932466506958,
      "learning_rate": 4.5202e-05,
      "loss": 0.6327,
      "step": 2400
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.627254009246826,
      "learning_rate": 4.5002e-05,
      "loss": 0.6657,
      "step": 2500
    },
    {
      "epoch": 0.208,
      "grad_norm": 6.739745140075684,
      "learning_rate": 4.4802e-05,
      "loss": 0.6541,
      "step": 2600
    },
    {
      "epoch": 0.216,
      "grad_norm": 3.9905107021331787,
      "learning_rate": 4.4602000000000004e-05,
      "loss": 0.6336,
      "step": 2700
    },
    {
      "epoch": 0.224,
      "grad_norm": 8.928628921508789,
      "learning_rate": 4.4402000000000006e-05,
      "loss": 0.6511,
      "step": 2800
    },
    {
      "epoch": 0.232,
      "grad_norm": 11.170398712158203,
      "learning_rate": 4.4202e-05,
      "loss": 0.6242,
      "step": 2900
    },
    {
      "epoch": 0.24,
      "grad_norm": 9.563961029052734,
      "learning_rate": 4.4002e-05,
      "loss": 0.6009,
      "step": 3000
    },
    {
      "epoch": 0.248,
      "grad_norm": 11.554056167602539,
      "learning_rate": 4.3802000000000005e-05,
      "loss": 0.6064,
      "step": 3100
    },
    {
      "epoch": 0.256,
      "grad_norm": 8.64344596862793,
      "learning_rate": 4.360200000000001e-05,
      "loss": 0.6438,
      "step": 3200
    },
    {
      "epoch": 0.264,
      "grad_norm": 3.343843936920166,
      "learning_rate": 4.3402e-05,
      "loss": 0.6116,
      "step": 3300
    },
    {
      "epoch": 0.272,
      "grad_norm": 8.708916664123535,
      "learning_rate": 4.3202000000000004e-05,
      "loss": 0.6413,
      "step": 3400
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.958003520965576,
      "learning_rate": 4.3002000000000006e-05,
      "loss": 0.6444,
      "step": 3500
    },
    {
      "epoch": 0.288,
      "grad_norm": 7.362785816192627,
      "learning_rate": 4.2802e-05,
      "loss": 0.6449,
      "step": 3600
    },
    {
      "epoch": 0.296,
      "grad_norm": 7.973524570465088,
      "learning_rate": 4.2602e-05,
      "loss": 0.6241,
      "step": 3700
    },
    {
      "epoch": 0.304,
      "grad_norm": 10.90877914428711,
      "learning_rate": 4.2402000000000005e-05,
      "loss": 0.6458,
      "step": 3800
    },
    {
      "epoch": 0.312,
      "grad_norm": 4.4147210121154785,
      "learning_rate": 4.2202e-05,
      "loss": 0.6157,
      "step": 3900
    },
    {
      "epoch": 0.32,
      "grad_norm": 11.774454116821289,
      "learning_rate": 4.2002e-05,
      "loss": 0.6525,
      "step": 4000
    },
    {
      "epoch": 0.328,
      "grad_norm": 7.39228630065918,
      "learning_rate": 4.1802000000000004e-05,
      "loss": 0.5902,
      "step": 4100
    },
    {
      "epoch": 0.336,
      "grad_norm": 6.0449113845825195,
      "learning_rate": 4.1602e-05,
      "loss": 0.6304,
      "step": 4200
    },
    {
      "epoch": 0.344,
      "grad_norm": 3.182192087173462,
      "learning_rate": 4.1402e-05,
      "loss": 0.6144,
      "step": 4300
    },
    {
      "epoch": 0.352,
      "grad_norm": 7.401289939880371,
      "learning_rate": 4.1202e-05,
      "loss": 0.6373,
      "step": 4400
    },
    {
      "epoch": 0.36,
      "grad_norm": 11.762848854064941,
      "learning_rate": 4.1002000000000005e-05,
      "loss": 0.6188,
      "step": 4500
    },
    {
      "epoch": 0.368,
      "grad_norm": 2.0337443351745605,
      "learning_rate": 4.0802e-05,
      "loss": 0.6219,
      "step": 4600
    },
    {
      "epoch": 0.376,
      "grad_norm": 5.984612941741943,
      "learning_rate": 4.0602e-05,
      "loss": 0.6233,
      "step": 4700
    },
    {
      "epoch": 0.384,
      "grad_norm": 7.765051364898682,
      "learning_rate": 4.0402000000000004e-05,
      "loss": 0.6111,
      "step": 4800
    },
    {
      "epoch": 0.392,
      "grad_norm": 4.162261962890625,
      "learning_rate": 4.0202e-05,
      "loss": 0.578,
      "step": 4900
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.359927654266357,
      "learning_rate": 4.0002e-05,
      "loss": 0.665,
      "step": 5000
    },
    {
      "epoch": 0.408,
      "grad_norm": 9.149951934814453,
      "learning_rate": 3.9802e-05,
      "loss": 0.6599,
      "step": 5100
    },
    {
      "epoch": 0.416,
      "grad_norm": 4.8006911277771,
      "learning_rate": 3.9602e-05,
      "loss": 0.6258,
      "step": 5200
    },
    {
      "epoch": 0.424,
      "grad_norm": 4.075295925140381,
      "learning_rate": 3.9402e-05,
      "loss": 0.617,
      "step": 5300
    },
    {
      "epoch": 0.432,
      "grad_norm": 7.288478851318359,
      "learning_rate": 3.9202e-05,
      "loss": 0.6373,
      "step": 5400
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.417593479156494,
      "learning_rate": 3.9002e-05,
      "loss": 0.6192,
      "step": 5500
    },
    {
      "epoch": 0.448,
      "grad_norm": 5.623091220855713,
      "learning_rate": 3.8802e-05,
      "loss": 0.6353,
      "step": 5600
    },
    {
      "epoch": 0.456,
      "grad_norm": 8.001840591430664,
      "learning_rate": 3.8602e-05,
      "loss": 0.5918,
      "step": 5700
    },
    {
      "epoch": 0.464,
      "grad_norm": 4.001518249511719,
      "learning_rate": 3.8401999999999996e-05,
      "loss": 0.6861,
      "step": 5800
    },
    {
      "epoch": 0.472,
      "grad_norm": 3.35774302482605,
      "learning_rate": 3.8202000000000005e-05,
      "loss": 0.6051,
      "step": 5900
    },
    {
      "epoch": 0.48,
      "grad_norm": 5.968842506408691,
      "learning_rate": 3.8002000000000006e-05,
      "loss": 0.5716,
      "step": 6000
    },
    {
      "epoch": 0.488,
      "grad_norm": 4.783994674682617,
      "learning_rate": 3.7802e-05,
      "loss": 0.6385,
      "step": 6100
    },
    {
      "epoch": 0.496,
      "grad_norm": 9.744927406311035,
      "learning_rate": 3.7602000000000004e-05,
      "loss": 0.5991,
      "step": 6200
    },
    {
      "epoch": 0.504,
      "grad_norm": 6.677623748779297,
      "learning_rate": 3.7402000000000005e-05,
      "loss": 0.6414,
      "step": 6300
    },
    {
      "epoch": 0.512,
      "grad_norm": 6.2413177490234375,
      "learning_rate": 3.7202e-05,
      "loss": 0.5833,
      "step": 6400
    },
    {
      "epoch": 0.52,
      "grad_norm": 6.632689476013184,
      "learning_rate": 3.7002e-05,
      "loss": 0.5966,
      "step": 6500
    },
    {
      "epoch": 0.528,
      "grad_norm": 5.0930562019348145,
      "learning_rate": 3.6802000000000004e-05,
      "loss": 0.6246,
      "step": 6600
    },
    {
      "epoch": 0.536,
      "grad_norm": 4.602765083312988,
      "learning_rate": 3.6602000000000006e-05,
      "loss": 0.5814,
      "step": 6700
    },
    {
      "epoch": 0.544,
      "grad_norm": 4.085660457611084,
      "learning_rate": 3.6402e-05,
      "loss": 0.5701,
      "step": 6800
    },
    {
      "epoch": 0.552,
      "grad_norm": 5.75092077255249,
      "learning_rate": 3.6202e-05,
      "loss": 0.5868,
      "step": 6900
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.31563138961792,
      "learning_rate": 3.6002000000000005e-05,
      "loss": 0.6655,
      "step": 7000
    },
    {
      "epoch": 0.568,
      "grad_norm": 3.1273510456085205,
      "learning_rate": 3.5802e-05,
      "loss": 0.6534,
      "step": 7100
    },
    {
      "epoch": 0.576,
      "grad_norm": 4.642505168914795,
      "learning_rate": 3.5602e-05,
      "loss": 0.5831,
      "step": 7200
    },
    {
      "epoch": 0.584,
      "grad_norm": 3.6079092025756836,
      "learning_rate": 3.5402000000000004e-05,
      "loss": 0.5778,
      "step": 7300
    },
    {
      "epoch": 0.592,
      "grad_norm": 5.516758918762207,
      "learning_rate": 3.5202e-05,
      "loss": 0.5246,
      "step": 7400
    },
    {
      "epoch": 0.6,
      "grad_norm": 7.69569206237793,
      "learning_rate": 3.5002e-05,
      "loss": 0.6421,
      "step": 7500
    },
    {
      "epoch": 0.608,
      "grad_norm": 17.524709701538086,
      "learning_rate": 3.4802e-05,
      "loss": 0.5667,
      "step": 7600
    },
    {
      "epoch": 0.616,
      "grad_norm": 11.053278923034668,
      "learning_rate": 3.4602e-05,
      "loss": 0.5589,
      "step": 7700
    },
    {
      "epoch": 0.624,
      "grad_norm": 6.322327613830566,
      "learning_rate": 3.4402e-05,
      "loss": 0.5775,
      "step": 7800
    },
    {
      "epoch": 0.632,
      "grad_norm": 5.679113864898682,
      "learning_rate": 3.4202e-05,
      "loss": 0.5861,
      "step": 7900
    },
    {
      "epoch": 0.64,
      "grad_norm": 10.221220016479492,
      "learning_rate": 3.4002e-05,
      "loss": 0.5891,
      "step": 8000
    },
    {
      "epoch": 0.648,
      "grad_norm": 3.6522512435913086,
      "learning_rate": 3.3802e-05,
      "loss": 0.585,
      "step": 8100
    },
    {
      "epoch": 0.656,
      "grad_norm": 6.187958717346191,
      "learning_rate": 3.3602e-05,
      "loss": 0.5962,
      "step": 8200
    },
    {
      "epoch": 0.664,
      "grad_norm": 9.430695533752441,
      "learning_rate": 3.3402e-05,
      "loss": 0.5713,
      "step": 8300
    },
    {
      "epoch": 0.672,
      "grad_norm": 3.915781021118164,
      "learning_rate": 3.3202e-05,
      "loss": 0.607,
      "step": 8400
    },
    {
      "epoch": 0.68,
      "grad_norm": 6.723072052001953,
      "learning_rate": 3.3002e-05,
      "loss": 0.541,
      "step": 8500
    },
    {
      "epoch": 0.688,
      "grad_norm": 9.994481086730957,
      "learning_rate": 3.2802e-05,
      "loss": 0.5916,
      "step": 8600
    },
    {
      "epoch": 0.696,
      "grad_norm": 9.02000617980957,
      "learning_rate": 3.2602e-05,
      "loss": 0.5783,
      "step": 8700
    },
    {
      "epoch": 0.704,
      "grad_norm": 8.831488609313965,
      "learning_rate": 3.2402e-05,
      "loss": 0.5545,
      "step": 8800
    },
    {
      "epoch": 0.712,
      "grad_norm": 2.8085715770721436,
      "learning_rate": 3.2202e-05,
      "loss": 0.5606,
      "step": 8900
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.292579174041748,
      "learning_rate": 3.2002e-05,
      "loss": 0.623,
      "step": 9000
    },
    {
      "epoch": 0.728,
      "grad_norm": 3.9556143283843994,
      "learning_rate": 3.1802000000000005e-05,
      "loss": 0.6144,
      "step": 9100
    },
    {
      "epoch": 0.736,
      "grad_norm": 4.502866268157959,
      "learning_rate": 3.160200000000001e-05,
      "loss": 0.5871,
      "step": 9200
    },
    {
      "epoch": 0.744,
      "grad_norm": 8.73207950592041,
      "learning_rate": 3.1402e-05,
      "loss": 0.5449,
      "step": 9300
    },
    {
      "epoch": 0.752,
      "grad_norm": 10.226662635803223,
      "learning_rate": 3.1202000000000004e-05,
      "loss": 0.6386,
      "step": 9400
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.793543815612793,
      "learning_rate": 3.1002000000000006e-05,
      "loss": 0.5617,
      "step": 9500
    },
    {
      "epoch": 0.768,
      "grad_norm": 8.149812698364258,
      "learning_rate": 3.0802e-05,
      "loss": 0.592,
      "step": 9600
    },
    {
      "epoch": 0.776,
      "grad_norm": 3.5575971603393555,
      "learning_rate": 3.0602e-05,
      "loss": 0.5825,
      "step": 9700
    },
    {
      "epoch": 0.784,
      "grad_norm": 2.293652057647705,
      "learning_rate": 3.0402e-05,
      "loss": 0.5606,
      "step": 9800
    },
    {
      "epoch": 0.792,
      "grad_norm": 5.711645603179932,
      "learning_rate": 3.0202000000000003e-05,
      "loss": 0.6005,
      "step": 9900
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.791075229644775,
      "learning_rate": 3.0002000000000002e-05,
      "loss": 0.6203,
      "step": 10000
    },
    {
      "epoch": 0.808,
      "grad_norm": 10.27843189239502,
      "learning_rate": 2.9802000000000004e-05,
      "loss": 0.546,
      "step": 10100
    },
    {
      "epoch": 0.816,
      "grad_norm": 7.96987771987915,
      "learning_rate": 2.9602000000000002e-05,
      "loss": 0.5527,
      "step": 10200
    },
    {
      "epoch": 0.824,
      "grad_norm": 13.316190719604492,
      "learning_rate": 2.9402e-05,
      "loss": 0.5672,
      "step": 10300
    },
    {
      "epoch": 0.832,
      "grad_norm": 9.738941192626953,
      "learning_rate": 2.9202000000000003e-05,
      "loss": 0.5612,
      "step": 10400
    },
    {
      "epoch": 0.84,
      "grad_norm": 5.243626117706299,
      "learning_rate": 2.9002e-05,
      "loss": 0.5377,
      "step": 10500
    },
    {
      "epoch": 0.848,
      "grad_norm": 17.936124801635742,
      "learning_rate": 2.8802e-05,
      "loss": 0.5547,
      "step": 10600
    },
    {
      "epoch": 0.856,
      "grad_norm": 6.802175998687744,
      "learning_rate": 2.8602e-05,
      "loss": 0.6098,
      "step": 10700
    },
    {
      "epoch": 0.864,
      "grad_norm": 5.557641506195068,
      "learning_rate": 2.8402e-05,
      "loss": 0.5474,
      "step": 10800
    },
    {
      "epoch": 0.872,
      "grad_norm": 7.617228984832764,
      "learning_rate": 2.8202000000000002e-05,
      "loss": 0.5241,
      "step": 10900
    },
    {
      "epoch": 0.88,
      "grad_norm": 5.69966459274292,
      "learning_rate": 2.8002e-05,
      "loss": 0.618,
      "step": 11000
    },
    {
      "epoch": 0.888,
      "grad_norm": 13.968184471130371,
      "learning_rate": 2.7802e-05,
      "loss": 0.5826,
      "step": 11100
    },
    {
      "epoch": 0.896,
      "grad_norm": 7.885385513305664,
      "learning_rate": 2.7602e-05,
      "loss": 0.5562,
      "step": 11200
    },
    {
      "epoch": 0.904,
      "grad_norm": 13.299610137939453,
      "learning_rate": 2.7402e-05,
      "loss": 0.5284,
      "step": 11300
    },
    {
      "epoch": 0.912,
      "grad_norm": 2.9911727905273438,
      "learning_rate": 2.7201999999999998e-05,
      "loss": 0.5788,
      "step": 11400
    },
    {
      "epoch": 0.92,
      "grad_norm": 7.246181011199951,
      "learning_rate": 2.7002e-05,
      "loss": 0.5285,
      "step": 11500
    },
    {
      "epoch": 0.928,
      "grad_norm": 5.779560089111328,
      "learning_rate": 2.6802e-05,
      "loss": 0.545,
      "step": 11600
    },
    {
      "epoch": 0.936,
      "grad_norm": 15.936969757080078,
      "learning_rate": 2.6602e-05,
      "loss": 0.5433,
      "step": 11700
    },
    {
      "epoch": 0.944,
      "grad_norm": 33.041255950927734,
      "learning_rate": 2.6402e-05,
      "loss": 0.5218,
      "step": 11800
    },
    {
      "epoch": 0.952,
      "grad_norm": 4.173487186431885,
      "learning_rate": 2.6201999999999997e-05,
      "loss": 0.5384,
      "step": 11900
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.574592113494873,
      "learning_rate": 2.6002e-05,
      "loss": 0.5584,
      "step": 12000
    },
    {
      "epoch": 0.968,
      "grad_norm": 6.6371588706970215,
      "learning_rate": 2.5802000000000005e-05,
      "loss": 0.5594,
      "step": 12100
    },
    {
      "epoch": 0.976,
      "grad_norm": 3.9571244716644287,
      "learning_rate": 2.5602000000000003e-05,
      "loss": 0.5789,
      "step": 12200
    },
    {
      "epoch": 0.984,
      "grad_norm": 2.6473522186279297,
      "learning_rate": 2.5402000000000005e-05,
      "loss": 0.5623,
      "step": 12300
    },
    {
      "epoch": 0.992,
      "grad_norm": 5.829174995422363,
      "learning_rate": 2.5202000000000004e-05,
      "loss": 0.5121,
      "step": 12400
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.237788200378418,
      "learning_rate": 2.5002000000000002e-05,
      "loss": 0.5771,
      "step": 12500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.79555,
      "eval_loss": 0.5601980090141296,
      "eval_runtime": 272.9679,
      "eval_samples_per_second": 73.269,
      "eval_steps_per_second": 9.159,
      "step": 12500
    }
  ],
  "logging_steps": 100,
  "max_steps": 25000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3247448576e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
